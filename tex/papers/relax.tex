\section{RELAX}
In this section we will review \citet{grathwohl2017relax}.

\paragraph{Motivation}
The aim of this paper is to find $\argmin\theta \Es{p(b \mid \theta)}{f(b)}$
via gradient descent using a Monte Carlo approximation of the gradient.
The focus is finding a low-variance unbiased estimator by combining
the score function estimator with the reparameterization trick.

The two applications considered in this paper are gradient
estimation for latent variable models and RL.

\paragraph{Contributions}
\citet{grathwohl2017relax} introduce a differentiable surrogate for $f$, and for discrete $b$
a reparameterizable relaxation $p_\theta(z)$ such that $H(z) = b$.
They use the differentiable surrogate (and $p_\theta(z)$ when applicable) as a control
variate and directly minimize the variance of the score function estimator.
The result is an unbiased and seemingly low-variance estimator.

Additionally, for discrete $b$,
they resample the relaxed $\tilde{z} \mid b$,
which allows them to further reduce variance by increasing the correlation between
their control variate and the score function estimator.

More concretely, let $b \sim \Cat(\theta), \theta \in \Delta^{n-1}$.
The score function estimator is
\begin{equation}
\nabla_\theta \Es{b}{f(b)} = \Es{b}{f(b)\nabla_\theta \log p(b\mid\theta)}
\end{equation}

The LAX estimator is given by introducing differentiable surrogate $c_\phi(z)$
with Gumbel-perturbed logits $z \sim p(z \mid \theta)$
\begin{equation}
\nabla_\theta \Es{b}{f(b)} = \Es{z}{f(b)\nabla_\theta \log p(b\mid\theta)
- c_\phi(z)\nabla_\theta \log p(z \mid \theta) + \nabla_\theta c_\phi(z)}
\end{equation}
where $b = H(z), z\sim p(z\mid\theta)$ and $H$ is a deterministic transformation.
For the case of $z\sim\Gumbel(\theta)$, $H(z) = \argmax_i(z_i)$.

The RELAX estimator is obtained by 

\paragraph{Results}
Show better training and validation performance on a mixture density model for MNIST
Better training but overfits on omniglot
Demonstrate faster convergence and lower variance gradient estimators than A2C for three RL tasks: cart-pole, lunar lander, and inverted pendulum

\paragraph{Limitations}

\paragraph{Future Directions}

\paragraph{Questions / Comments}

